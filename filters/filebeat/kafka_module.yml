# Kafka module filter, version 3.0.0
# Filter Input requirements -> fileset: datatype
#                              log: plain text
# 
# Compatible any of Kafka logs 
# like: Server, Controller, Log-cleaner and so on
# 
# Documentations
# 1- https://kafka.apache.org/documentation/
# 2- https://www.elastic.co/guide/en/beats/filebeat/7.13/exported-fields-kafka.html
# 
# Implementation
# 1. Parsing the json from beats
# 2. Parsing the message field containing the apache log
pipeline:
  - dataTypes:
      - kafka
    steps:
      - json:
          source: raw

      # Parse beats field    
      - rename:
          from:
            - log.log.file.path
          to: local.file
      - rename:
          from:
            - log.host.ip
          to: local.ips
      - rename:
          from:
            - log.host.mac
          to: local.macs
      - rename:
          from:
            - log.host.hostname
          to: local.host
      - rename:
          from:
            - log.event.dataset
          to: action
      - rename:
          from:
            - log.agent.version
          to: log.agentVersion
      - rename:
          from:
            - log.host.os.kernel
          to: log.osVersion
      - rename:
          from:
            - log.host.os.type
          to: log.osType
      - rename:
          from:
            - log.host.architecture
          to: log.cpuArchitecture

      - cast:
          to: '[]string'
          fields:
            - local.ips
      - cast:
          to: '[]string'
          fields:
            - local.macs
      
      #Parse message field in plain text format
      # Logs Kafka parsing
      - grok:
          patterns:
            - fieldName: log.deviceTime
              pattern: '\[{{.data}}\]'
            - fieldName: log.logLevel
              pattern: '{{.word}}'
            - fieldName: log.restData
              pattern: '{{.greedy}}'
          source: log.message
          
      # Logs Server Kafka parsing
      - grok:
          patterns:
            - fieldName: log.msg
              pattern: '{{.greedy}}'
          source: log.restData

      # Logs Controller Kafka parsing
      - grok:
          patterns:
            - fieldName: log.component
              pattern: '\[{{.data}}\]'
            - fieldName: log.msg
              pattern: '{{.greedy}}'
          source: log.restData
      
      # Removing unused caracters
      - trim:
          function: prefix
          substring: '['
          fields:
            - log.deviceTime
            - log.component
      - trim:
          function: suffix
          substring: ']'
          fields:
            - log.deviceTime
            - log.component
      
      # Removing unused fields
      - delete:
          fields:
            - log.service
            - log.metadata
            - log.log.offset
            - log.agent
            - log.host
            - log.event
            - log.ecs
            - log.log.file
            - log.restData